{
 "metadata": {
  "name": "",
  "signature": "sha256:27b48eae2ff8b439ed4e4bde1fdfa5d81fa143965809cbcd38d73e162745056b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Getting Data into your notebook."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The following are examples of how to deal with various data sources.  Feel free to grab this notebook, or portions, and adapt as needed. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In R, getwd() and setwd() allow you to see where you're working and the ability to change your working directory. The following will allow us to see the current working directory and change as needed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "'/Users/Bryan/Desktop'"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.chdir('/Users/Bryan/Desktop')\n",
      "os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "'/Users/Bryan/Desktop'"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Reading in csv files. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pandas will be your primary method for pulling in .csv files.\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "Twitter = r'tweets_from_bigdata_[2014-10-16_16h14_to_2014-11-25_15h15]_p79350-1416925145.csv'\n",
      "tweetframe = pd.read_csv(Twitter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetframe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Tweet ID</th>\n",
        "      <th>Date (UTC)</th>\n",
        "      <th>From (@username)</th>\n",
        "      <th>From (name)</th>\n",
        "      <th>Text</th>\n",
        "      <th>Geo coordinates</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0     </th>\n",
        "      <td> 522752475133411000</td>\n",
        "      <td> 10/16/14 14:14</td>\n",
        "      <td>     TanejaGroup</td>\n",
        "      <td>       Taneja Group</td>\n",
        "      <td> TG Blog | @BlueDataInc : #BigData #Analysis Cl...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1     </th>\n",
        "      <td> 522752480212692000</td>\n",
        "      <td> 10/16/14 14:14</td>\n",
        "      <td>      jojennings</td>\n",
        "      <td>    Joanne Jennings</td>\n",
        "      <td> RT @UnaBoylan: This is how #BigData could help...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2     </th>\n",
        "      <td> 522752486579634000</td>\n",
        "      <td> 10/16/14 14:14</td>\n",
        "      <td>       IEHeather</td>\n",
        "      <td>      Heather James</td>\n",
        "      <td> Free online magazine: Big Data Innovation, Iss...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3     </th>\n",
        "      <td> 522752489477906000</td>\n",
        "      <td> 10/16/14 14:14</td>\n",
        "      <td>        SarahCtn</td>\n",
        "      <td>     Sarah Cr\u0329tinon</td>\n",
        "      <td> RT @orange: Le mobile, la solution aux \u0329pid\u0329mi...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4     </th>\n",
        "      <td> 522752522633494000</td>\n",
        "      <td> 10/16/14 14:14</td>\n",
        "      <td>      strataconf</td>\n",
        "      <td>    O'Reilly Strata</td>\n",
        "      <td> RT @mphnyc: @BobMankoff onstage at #HadoopWorl...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5     </th>\n",
        "      <td> 522752568640815000</td>\n",
        "      <td> 10/16/14 14:14</td>\n",
        "      <td>   Space_Plowboy</td>\n",
        "      <td>      Terry Griffin</td>\n",
        "      <td> I will be speaking on #bigdata in  #precisiona...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6     </th>\n",
        "      <td> 522752574953619000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>     SAPInMemory</td>\n",
        "      <td>           SAP HANA</td>\n",
        "      <td> .@CSX @ConvergenceCT @CSC are changing the way...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7     </th>\n",
        "      <td> 522752578682368000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>    MobilityWise</td>\n",
        "      <td> Accenture Mobility</td>\n",
        "      <td> Today at 1230 pm ET, #Accenture is hosting a t...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8     </th>\n",
        "      <td> 522752611209183000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>        IEDeanna</td>\n",
        "      <td>      Deanna Notice</td>\n",
        "      <td> RT @IEHeather: Free online magazine: Big Data ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9     </th>\n",
        "      <td> 522752629429260000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>       IEHeather</td>\n",
        "      <td>      Heather James</td>\n",
        "      <td> 11 Ways Data Has Changed How We Travel  http:/...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10    </th>\n",
        "      <td> 522752630184239000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>  p2pWebMobileIt</td>\n",
        "      <td>    p2p WebMobileIT</td>\n",
        "      <td> Solutions Architect (3 month contract) M/F w/ ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11    </th>\n",
        "      <td> 522752632298176000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>       bobehayes</td>\n",
        "      <td>  Bob E. Hayes, PhD</td>\n",
        "      <td> Is #BigData squishing our humanity? http://t.c...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12    </th>\n",
        "      <td> 522752636043657000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>      caelenface</td>\n",
        "      <td>       Caelen Dwane</td>\n",
        "      <td> RT @UnaBoylan: This is how #BigData could help...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13    </th>\n",
        "      <td> 522752640485429000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>    IKnowBigData</td>\n",
        "      <td>      Know Big Data</td>\n",
        "      <td> The Free #bigdata #hadoop session is about to ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14    </th>\n",
        "      <td> 522752641705586000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>  neeraj_malviya</td>\n",
        "      <td>     Neeraj Malviya</td>\n",
        "      <td> RT @KirkDBorne: #MachineLearning #BigData Rese...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15    </th>\n",
        "      <td> 522752682839515000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>      RunningMBA</td>\n",
        "      <td>    Jennifer Havens</td>\n",
        "      <td> Just sat through a great session on agile anal...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16    </th>\n",
        "      <td> 522752747792531000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>        MedicReS</td>\n",
        "      <td>           MedicReS</td>\n",
        "      <td> #LIVE... The Age of #BigData @nytimes , Februa...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17    </th>\n",
        "      <td> 522752751139573000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>       SASCanada</td>\n",
        "      <td>         SAS Canada</td>\n",
        "      <td> #NEWS! Toronto Maple Leafs Partners with @SASC...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18    </th>\n",
        "      <td> 522752763189821000</td>\n",
        "      <td> 10/16/14 14:15</td>\n",
        "      <td>      NetFaculty</td>\n",
        "      <td>    Network Faculty</td>\n",
        "      <td> Chief analytics officer: The ultimate #bigdata...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19    </th>\n",
        "      <td> 522752825521352000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td>    martingallen</td>\n",
        "      <td>       Martin Allen</td>\n",
        "      <td> Aggregate&amp;gt;Enrich&amp;gt;Analyse #datascience #b...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20    </th>\n",
        "      <td> 522752872011038000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td>     KamilIsaev1</td>\n",
        "      <td>        Kamil Isaev</td>\n",
        "      <td> We had a special guest today\\rKarin Breitman, ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21    </th>\n",
        "      <td> 522752875278389000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td> TungstenBigData</td>\n",
        "      <td>    TungstenBigData</td>\n",
        "      <td> Information Builders Announces Omni-Patient Pr...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22    </th>\n",
        "      <td> 522752887651586000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td> TungstenBigData</td>\n",
        "      <td>    TungstenBigData</td>\n",
        "      <td> Datawatch Discusses the Future of Visualizatio...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23    </th>\n",
        "      <td> 522752888708534000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td>          AlsLou</td>\n",
        "      <td>       Aless Loayza</td>\n",
        "      <td> Que tremendo potencial tiene qlik  datos y mas...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24    </th>\n",
        "      <td> 522752896174411000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td> TungstenBigData</td>\n",
        "      <td>    TungstenBigData</td>\n",
        "      <td> ScaleOut Software Releases Version 5.2 of Its ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25    </th>\n",
        "      <td> 522752900611964000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td>     andrekearns</td>\n",
        "      <td>       Andre Kearns</td>\n",
        "      <td> The Quiet Rise of the National Geospatial-Inte...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26    </th>\n",
        "      <td> 522752908350480000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td> amasoliverdilme</td>\n",
        "      <td>   Albert Masoliver</td>\n",
        "      <td> Collaborations and correlations in the common ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27    </th>\n",
        "      <td> 522752910795358000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td>        FadilaMM</td>\n",
        "      <td>      Insight Story</td>\n",
        "      <td> Flux Vision: \u0329tudes de march\u0329 et croisement de...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28    </th>\n",
        "      <td> 522752913257795000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td> JGMARTINEZOCHOA</td>\n",
        "      <td>  JGMARTINEZOCHOA#1</td>\n",
        "      <td> RT @couchbase: PayPal uses #BigData to their a...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29    </th>\n",
        "      <td> 522752925186392000</td>\n",
        "      <td> 10/16/14 14:16</td>\n",
        "      <td>       DHenschen</td>\n",
        "      <td>      Doug Henschen</td>\n",
        "      <td> Azure #bigdata service goes real time @Microso...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390011</th>\n",
        "      <td> 537247271511797000</td>\n",
        "      <td> 11/25/14 14:11</td>\n",
        "      <td>         cuongcz</td>\n",
        "      <td>         Cuong Alan</td>\n",
        "      <td> FICO Improves Its #BigData Score with Trio of ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390012</th>\n",
        "      <td> 537247288020979000</td>\n",
        "      <td> 11/25/14 14:11</td>\n",
        "      <td>   biconnections</td>\n",
        "      <td>      BIconnections</td>\n",
        "      <td> RT @bjonesnDC: Why Predictive Analytics is Bet...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390013</th>\n",
        "      <td> 537247304622026000</td>\n",
        "      <td> 11/25/14 14:11</td>\n",
        "      <td>      maxidamico</td>\n",
        "      <td>       Max D' Amico</td>\n",
        "      <td> RT @bryantafel: Los tel\u0329fonos celulares y la c...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390014</th>\n",
        "      <td> 537247310431133000</td>\n",
        "      <td> 11/25/14 14:11</td>\n",
        "      <td>        esselinj</td>\n",
        "      <td>      Jack Esselink</td>\n",
        "      <td> A Match Made Somewhere: Big Data and the Inter...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390015</th>\n",
        "      <td> 537247363807469000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @cuongcz: FICO Improves Its #BigData Score ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390016</th>\n",
        "      <td> 537247364839260000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @jainrasik: \"How to weather the big data st...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390017</th>\n",
        "      <td> 537247365464207000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @kimdossey: The Hive #BigData Think Tank De...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390018</th>\n",
        "      <td> 537247366735089000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @VishalTx: 10 Prerequisites Before Getting ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390019</th>\n",
        "      <td> 537247367414562000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @mikepluta: Top story from @CRN #BigData St...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390020</th>\n",
        "      <td> 537247368253419000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @IDGMobility: Goldman Sachs Invests in Big ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390021</th>\n",
        "      <td> 537247368932900000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @IE_BigData: Three Ways To Use Big Data To ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390022</th>\n",
        "      <td> 537247369532694000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @jmtwn: Up your game with Digital Transform...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390023</th>\n",
        "      <td> 537247370216767000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td>      Julian0Bro</td>\n",
        "      <td>             Julian</td>\n",
        "      <td> #BigData is a term just like #Talent in HR &amp;gt...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390024</th>\n",
        "      <td> 537247370921410000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> michaelyoungMBN</td>\n",
        "      <td>      Michael Young</td>\n",
        "      <td> How To Weather The Big Data Storm http://t.co/...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390025</th>\n",
        "      <td> 537247370946154000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @HP: #BigData is revealing big numbers on h...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390026</th>\n",
        "      <td> 537247371575300000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @HITAnalytics: #EHR #DataAnalytics Flag Hid...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390027</th>\n",
        "      <td> 537247387862179000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td>          Hoorge</td>\n",
        "      <td>    Harjit Dhaliwal</td>\n",
        "      <td> RT @MSFTnews: See how @CarnegieMellon is using...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390028</th>\n",
        "      <td> 537247400545353000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td> accusoftinfoway</td>\n",
        "      <td> Accusoft Infoways </td>\n",
        "      <td> RT @ade_carr: Data Is Good, 'Bidirectionalized...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390029</th>\n",
        "      <td> 537247404550938000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td>     Greyhound_R</td>\n",
        "      <td> Greyhound Research</td>\n",
        "      <td> #BigData impacts one and all #Financial #Healt...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390030</th>\n",
        "      <td> 537247420389015000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td>       jwilhelmi</td>\n",
        "      <td>      John Wilhelmi</td>\n",
        "      <td> RT @MSFTnews: See how @CarnegieMellon is using...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390031</th>\n",
        "      <td> 537247518464020000</td>\n",
        "      <td> 11/25/14 14:12</td>\n",
        "      <td>     Greyhound_R</td>\n",
        "      <td> Greyhound Research</td>\n",
        "      <td> #BigData is a reality and affects customer eng...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390032</th>\n",
        "      <td> 537247715458293000</td>\n",
        "      <td> 11/25/14 14:13</td>\n",
        "      <td> telecomitaliaTw</td>\n",
        "      <td> TelecomItaliaGroup</td>\n",
        "      <td> Al #DemoDay14 di @workingcapital @stellaromagn...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390033</th>\n",
        "      <td> 537247769376079000</td>\n",
        "      <td> 11/25/14 14:13</td>\n",
        "      <td>   CarinaJenkins</td>\n",
        "      <td>     Carina Jenkins</td>\n",
        "      <td> RT @LondonInfoInter: Connecting Knowledge Silo...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390034</th>\n",
        "      <td> 537247823486390000</td>\n",
        "      <td> 11/25/14 14:13</td>\n",
        "      <td>    JuniorHendry</td>\n",
        "      <td>              Allen</td>\n",
        "      <td> RT @MSFTnews: See how @CarnegieMellon is using...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390035</th>\n",
        "      <td> 537247911374225000</td>\n",
        "      <td> 11/25/14 14:14</td>\n",
        "      <td>       iotattack</td>\n",
        "      <td>         IoT Attack</td>\n",
        "      <td> #IoT Bitdefender Unveils IoT Security Applianc...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390036</th>\n",
        "      <td> 537247915572731000</td>\n",
        "      <td> 11/25/14 14:14</td>\n",
        "      <td>       iotattack</td>\n",
        "      <td>         IoT Attack</td>\n",
        "      <td> #IoT Rogers Pledges CAD $4M to Spur Growth of ...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390037</th>\n",
        "      <td> 537247934346457000</td>\n",
        "      <td> 11/25/14 14:14</td>\n",
        "      <td>       iotattack</td>\n",
        "      <td>         IoT Attack</td>\n",
        "      <td> IoT &amp;amp; Big Data\\rhttps://t.co/1BNCQ5VEVs\\r#...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390038</th>\n",
        "      <td> 537247940423987000</td>\n",
        "      <td> 11/25/14 14:14</td>\n",
        "      <td>         Fidanto</td>\n",
        "      <td>          Antonella</td>\n",
        "      <td> #bigdata #programmatico sembra di sentir parla...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390039</th>\n",
        "      <td> 537248046401081000</td>\n",
        "      <td> 11/25/14 14:14</td>\n",
        "      <td>         LogicPD</td>\n",
        "      <td>           Logic PD</td>\n",
        "      <td> RT @GerardoNZ: Machines do analytics; humans d...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>390040</th>\n",
        "      <td> 537248054319906000</td>\n",
        "      <td> 11/25/14 14:14</td>\n",
        "      <td>     Greyhound_R</td>\n",
        "      <td> Greyhound Research</td>\n",
        "      <td> Do not talk to your business about #BigData #I...</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>390041 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "                  Tweet ID      Date (UTC) From (@username)  \\\n",
        "0       522752475133411000  10/16/14 14:14      TanejaGroup   \n",
        "1       522752480212692000  10/16/14 14:14       jojennings   \n",
        "2       522752486579634000  10/16/14 14:14        IEHeather   \n",
        "3       522752489477906000  10/16/14 14:14         SarahCtn   \n",
        "4       522752522633494000  10/16/14 14:14       strataconf   \n",
        "5       522752568640815000  10/16/14 14:14    Space_Plowboy   \n",
        "6       522752574953619000  10/16/14 14:15      SAPInMemory   \n",
        "7       522752578682368000  10/16/14 14:15     MobilityWise   \n",
        "8       522752611209183000  10/16/14 14:15         IEDeanna   \n",
        "9       522752629429260000  10/16/14 14:15        IEHeather   \n",
        "10      522752630184239000  10/16/14 14:15   p2pWebMobileIt   \n",
        "11      522752632298176000  10/16/14 14:15        bobehayes   \n",
        "12      522752636043657000  10/16/14 14:15       caelenface   \n",
        "13      522752640485429000  10/16/14 14:15     IKnowBigData   \n",
        "14      522752641705586000  10/16/14 14:15   neeraj_malviya   \n",
        "15      522752682839515000  10/16/14 14:15       RunningMBA   \n",
        "16      522752747792531000  10/16/14 14:15         MedicReS   \n",
        "17      522752751139573000  10/16/14 14:15        SASCanada   \n",
        "18      522752763189821000  10/16/14 14:15       NetFaculty   \n",
        "19      522752825521352000  10/16/14 14:16     martingallen   \n",
        "20      522752872011038000  10/16/14 14:16      KamilIsaev1   \n",
        "21      522752875278389000  10/16/14 14:16  TungstenBigData   \n",
        "22      522752887651586000  10/16/14 14:16  TungstenBigData   \n",
        "23      522752888708534000  10/16/14 14:16           AlsLou   \n",
        "24      522752896174411000  10/16/14 14:16  TungstenBigData   \n",
        "25      522752900611964000  10/16/14 14:16      andrekearns   \n",
        "26      522752908350480000  10/16/14 14:16  amasoliverdilme   \n",
        "27      522752910795358000  10/16/14 14:16         FadilaMM   \n",
        "28      522752913257795000  10/16/14 14:16  JGMARTINEZOCHOA   \n",
        "29      522752925186392000  10/16/14 14:16        DHenschen   \n",
        "...                    ...             ...              ...   \n",
        "390011  537247271511797000  11/25/14 14:11          cuongcz   \n",
        "390012  537247288020979000  11/25/14 14:11    biconnections   \n",
        "390013  537247304622026000  11/25/14 14:11       maxidamico   \n",
        "390014  537247310431133000  11/25/14 14:11         esselinj   \n",
        "390015  537247363807469000  11/25/14 14:12  accusoftinfoway   \n",
        "390016  537247364839260000  11/25/14 14:12  accusoftinfoway   \n",
        "390017  537247365464207000  11/25/14 14:12  accusoftinfoway   \n",
        "390018  537247366735089000  11/25/14 14:12  accusoftinfoway   \n",
        "390019  537247367414562000  11/25/14 14:12  accusoftinfoway   \n",
        "390020  537247368253419000  11/25/14 14:12  accusoftinfoway   \n",
        "390021  537247368932900000  11/25/14 14:12  accusoftinfoway   \n",
        "390022  537247369532694000  11/25/14 14:12  accusoftinfoway   \n",
        "390023  537247370216767000  11/25/14 14:12       Julian0Bro   \n",
        "390024  537247370921410000  11/25/14 14:12  michaelyoungMBN   \n",
        "390025  537247370946154000  11/25/14 14:12  accusoftinfoway   \n",
        "390026  537247371575300000  11/25/14 14:12  accusoftinfoway   \n",
        "390027  537247387862179000  11/25/14 14:12           Hoorge   \n",
        "390028  537247400545353000  11/25/14 14:12  accusoftinfoway   \n",
        "390029  537247404550938000  11/25/14 14:12      Greyhound_R   \n",
        "390030  537247420389015000  11/25/14 14:12        jwilhelmi   \n",
        "390031  537247518464020000  11/25/14 14:12      Greyhound_R   \n",
        "390032  537247715458293000  11/25/14 14:13  telecomitaliaTw   \n",
        "390033  537247769376079000  11/25/14 14:13    CarinaJenkins   \n",
        "390034  537247823486390000  11/25/14 14:13     JuniorHendry   \n",
        "390035  537247911374225000  11/25/14 14:14        iotattack   \n",
        "390036  537247915572731000  11/25/14 14:14        iotattack   \n",
        "390037  537247934346457000  11/25/14 14:14        iotattack   \n",
        "390038  537247940423987000  11/25/14 14:14          Fidanto   \n",
        "390039  537248046401081000  11/25/14 14:14          LogicPD   \n",
        "390040  537248054319906000  11/25/14 14:14      Greyhound_R   \n",
        "\n",
        "               From (name)                                               Text  \\\n",
        "0             Taneja Group  TG Blog | @BlueDataInc : #BigData #Analysis Cl...   \n",
        "1          Joanne Jennings  RT @UnaBoylan: This is how #BigData could help...   \n",
        "2            Heather James  Free online magazine: Big Data Innovation, Iss...   \n",
        "3           Sarah Cr\u0329tinon  RT @orange: Le mobile, la solution aux \u0329pid\u0329mi...   \n",
        "4          O'Reilly Strata  RT @mphnyc: @BobMankoff onstage at #HadoopWorl...   \n",
        "5            Terry Griffin  I will be speaking on #bigdata in  #precisiona...   \n",
        "6                 SAP HANA  .@CSX @ConvergenceCT @CSC are changing the way...   \n",
        "7       Accenture Mobility  Today at 1230 pm ET, #Accenture is hosting a t...   \n",
        "8            Deanna Notice  RT @IEHeather: Free online magazine: Big Data ...   \n",
        "9            Heather James  11 Ways Data Has Changed How We Travel  http:/...   \n",
        "10         p2p WebMobileIT  Solutions Architect (3 month contract) M/F w/ ...   \n",
        "11       Bob E. Hayes, PhD  Is #BigData squishing our humanity? http://t.c...   \n",
        "12            Caelen Dwane  RT @UnaBoylan: This is how #BigData could help...   \n",
        "13           Know Big Data  The Free #bigdata #hadoop session is about to ...   \n",
        "14          Neeraj Malviya  RT @KirkDBorne: #MachineLearning #BigData Rese...   \n",
        "15         Jennifer Havens  Just sat through a great session on agile anal...   \n",
        "16                MedicReS  #LIVE... The Age of #BigData @nytimes , Februa...   \n",
        "17              SAS Canada  #NEWS! Toronto Maple Leafs Partners with @SASC...   \n",
        "18         Network Faculty  Chief analytics officer: The ultimate #bigdata...   \n",
        "19            Martin Allen  Aggregate&gt;Enrich&gt;Analyse #datascience #b...   \n",
        "20             Kamil Isaev  We had a special guest today\\rKarin Breitman, ...   \n",
        "21         TungstenBigData  Information Builders Announces Omni-Patient Pr...   \n",
        "22         TungstenBigData  Datawatch Discusses the Future of Visualizatio...   \n",
        "23            Aless Loayza  Que tremendo potencial tiene qlik  datos y mas...   \n",
        "24         TungstenBigData  ScaleOut Software Releases Version 5.2 of Its ...   \n",
        "25            Andre Kearns  The Quiet Rise of the National Geospatial-Inte...   \n",
        "26        Albert Masoliver  Collaborations and correlations in the common ...   \n",
        "27           Insight Story  Flux Vision: \u0329tudes de march\u0329 et croisement de...   \n",
        "28       JGMARTINEZOCHOA#1  RT @couchbase: PayPal uses #BigData to their a...   \n",
        "29           Doug Henschen  Azure #bigdata service goes real time @Microso...   \n",
        "...                    ...                                                ...   \n",
        "390011          Cuong Alan  FICO Improves Its #BigData Score with Trio of ...   \n",
        "390012       BIconnections  RT @bjonesnDC: Why Predictive Analytics is Bet...   \n",
        "390013        Max D' Amico  RT @bryantafel: Los tel\u0329fonos celulares y la c...   \n",
        "390014       Jack Esselink  A Match Made Somewhere: Big Data and the Inter...   \n",
        "390015  Accusoft Infoways   RT @cuongcz: FICO Improves Its #BigData Score ...   \n",
        "390016  Accusoft Infoways   RT @jainrasik: \"How to weather the big data st...   \n",
        "390017  Accusoft Infoways   RT @kimdossey: The Hive #BigData Think Tank De...   \n",
        "390018  Accusoft Infoways   RT @VishalTx: 10 Prerequisites Before Getting ...   \n",
        "390019  Accusoft Infoways   RT @mikepluta: Top story from @CRN #BigData St...   \n",
        "390020  Accusoft Infoways   RT @IDGMobility: Goldman Sachs Invests in Big ...   \n",
        "390021  Accusoft Infoways   RT @IE_BigData: Three Ways To Use Big Data To ...   \n",
        "390022  Accusoft Infoways   RT @jmtwn: Up your game with Digital Transform...   \n",
        "390023              Julian  #BigData is a term just like #Talent in HR &gt...   \n",
        "390024       Michael Young  How To Weather The Big Data Storm http://t.co/...   \n",
        "390025  Accusoft Infoways   RT @HP: #BigData is revealing big numbers on h...   \n",
        "390026  Accusoft Infoways   RT @HITAnalytics: #EHR #DataAnalytics Flag Hid...   \n",
        "390027     Harjit Dhaliwal  RT @MSFTnews: See how @CarnegieMellon is using...   \n",
        "390028  Accusoft Infoways   RT @ade_carr: Data Is Good, 'Bidirectionalized...   \n",
        "390029  Greyhound Research  #BigData impacts one and all #Financial #Healt...   \n",
        "390030       John Wilhelmi  RT @MSFTnews: See how @CarnegieMellon is using...   \n",
        "390031  Greyhound Research  #BigData is a reality and affects customer eng...   \n",
        "390032  TelecomItaliaGroup  Al #DemoDay14 di @workingcapital @stellaromagn...   \n",
        "390033      Carina Jenkins  RT @LondonInfoInter: Connecting Knowledge Silo...   \n",
        "390034               Allen  RT @MSFTnews: See how @CarnegieMellon is using...   \n",
        "390035          IoT Attack  #IoT Bitdefender Unveils IoT Security Applianc...   \n",
        "390036          IoT Attack  #IoT Rogers Pledges CAD $4M to Spur Growth of ...   \n",
        "390037          IoT Attack  IoT &amp; Big Data\\rhttps://t.co/1BNCQ5VEVs\\r#...   \n",
        "390038           Antonella  #bigdata #programmatico sembra di sentir parla...   \n",
        "390039            Logic PD  RT @GerardoNZ: Machines do analytics; humans d...   \n",
        "390040  Greyhound Research  Do not talk to your business about #BigData #I...   \n",
        "\n",
        "       Geo coordinates  \n",
        "0                  NaN  \n",
        "1                  NaN  \n",
        "2                  NaN  \n",
        "3                  NaN  \n",
        "4                  NaN  \n",
        "5                  NaN  \n",
        "6                  NaN  \n",
        "7                  NaN  \n",
        "8                  NaN  \n",
        "9                  NaN  \n",
        "10                 NaN  \n",
        "11                 NaN  \n",
        "12                 NaN  \n",
        "13                 NaN  \n",
        "14                 NaN  \n",
        "15                 NaN  \n",
        "16                 NaN  \n",
        "17                 NaN  \n",
        "18                 NaN  \n",
        "19                 NaN  \n",
        "20                 NaN  \n",
        "21                 NaN  \n",
        "22                 NaN  \n",
        "23                 NaN  \n",
        "24                 NaN  \n",
        "25                 NaN  \n",
        "26                 NaN  \n",
        "27                 NaN  \n",
        "28                 NaN  \n",
        "29                 NaN  \n",
        "...                ...  \n",
        "390011             NaN  \n",
        "390012             NaN  \n",
        "390013             NaN  \n",
        "390014             NaN  \n",
        "390015             NaN  \n",
        "390016             NaN  \n",
        "390017             NaN  \n",
        "390018             NaN  \n",
        "390019             NaN  \n",
        "390020             NaN  \n",
        "390021             NaN  \n",
        "390022             NaN  \n",
        "390023             NaN  \n",
        "390024             NaN  \n",
        "390025             NaN  \n",
        "390026             NaN  \n",
        "390027             NaN  \n",
        "390028             NaN  \n",
        "390029             NaN  \n",
        "390030             NaN  \n",
        "390031             NaN  \n",
        "390032             NaN  \n",
        "390033             NaN  \n",
        "390034             NaN  \n",
        "390035             NaN  \n",
        "390036             NaN  \n",
        "390037             NaN  \n",
        "390038             NaN  \n",
        "390039             NaN  \n",
        "390040             NaN  \n",
        "\n",
        "[390041 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Downloading data off the web.  In this case, we'll use the fixed speed cameras in Baltimore.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "\n",
      "# downloading the file as ..._camera.xls and save it in a subfolder of your choosing.\n",
      "fileUrl = 'https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xls?accessType=DOWNLOAD'\n",
      "f = urllib2.urlopen(fileUrl)\n",
      "data = f.read()\n",
      "with open('Baltimore_Fixed_Speed_Cameras.xls', 'wb') as w:\n",
      "    w.write(data)\n",
      "\n",
      "# load the Excel file as a pandas DataFrame\n",
      "baltData = pd.ExcelFile('Baltimore_Fixed_Speed_Cameras.xls')\n",
      "baltData = baltData.parse('Baltimore Fixed Speed Cameras', index_col=None, na_values=['NA'])\n",
      "baltData.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>address</th>\n",
        "      <th>direction</th>\n",
        "      <th>street</th>\n",
        "      <th>crossStreet</th>\n",
        "      <th>intersection</th>\n",
        "      <th>Location 1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>       S CATON AVE &amp; BENSON AVE</td>\n",
        "      <td> N/B</td>\n",
        "      <td>   Caton Ave</td>\n",
        "      <td>   Benson Ave</td>\n",
        "      <td>     Caton Ave &amp; Benson Ave</td>\n",
        "      <td> (39.2693779962, -76.6688185297)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>       S CATON AVE &amp; BENSON AVE</td>\n",
        "      <td> S/B</td>\n",
        "      <td>   Caton Ave</td>\n",
        "      <td>   Benson Ave</td>\n",
        "      <td>     Caton Ave &amp; Benson Ave</td>\n",
        "      <td> (39.2693157898, -76.6689698176)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> WILKENS AVE &amp; PINE HEIGHTS AVE</td>\n",
        "      <td> E/B</td>\n",
        "      <td> Wilkens Ave</td>\n",
        "      <td> Pine Heights</td>\n",
        "      <td> Wilkens Ave &amp; Pine Heights</td>\n",
        "      <td>  (39.2720252302, -76.676960806)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>        THE ALAMEDA &amp; E 33RD ST</td>\n",
        "      <td> S/B</td>\n",
        "      <td> The Alameda</td>\n",
        "      <td>      33rd St</td>\n",
        "      <td>     The Alameda  &amp; 33rd St</td>\n",
        "      <td> (39.3285013141, -76.5953545714)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>        E 33RD ST &amp; THE ALAMEDA</td>\n",
        "      <td> E/B</td>\n",
        "      <td>      E 33rd</td>\n",
        "      <td>  The Alameda</td>\n",
        "      <td>      E 33rd  &amp; The Alameda</td>\n",
        "      <td> (39.3283410623, -76.5953594625)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "                          address direction       street   crossStreet  \\\n",
        "0        S CATON AVE & BENSON AVE       N/B    Caton Ave    Benson Ave   \n",
        "1        S CATON AVE & BENSON AVE       S/B    Caton Ave    Benson Ave   \n",
        "2  WILKENS AVE & PINE HEIGHTS AVE       E/B  Wilkens Ave  Pine Heights   \n",
        "3         THE ALAMEDA & E 33RD ST       S/B  The Alameda       33rd St   \n",
        "4         E 33RD ST & THE ALAMEDA       E/B       E 33rd   The Alameda   \n",
        "\n",
        "                 intersection                       Location 1  \n",
        "0      Caton Ave & Benson Ave  (39.2693779962, -76.6688185297)  \n",
        "1      Caton Ave & Benson Ave  (39.2693157898, -76.6689698176)  \n",
        "2  Wilkens Ave & Pine Heights   (39.2720252302, -76.676960806)  \n",
        "3      The Alameda  & 33rd St  (39.3285013141, -76.5953545714)  \n",
        "4       E 33rd  & The Alameda  (39.3283410623, -76.5953594625)  "
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Super handy JSON"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, as an example, we'll generate JSON from the same Baltimore website"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "# go and get your data\n",
      "fileUrl = 'https://data.baltimorecity.gov/api/views/dz54-2aru/rows.json?accessType=DOWNLOAD'\n",
      "req = urllib2.Request(fileUrl)\n",
      "pull = urllib2.build_opener()\n",
      "f = pull.open(req)\n",
      "\n",
      "# read it in\n",
      "baltJson = json.loads(f.read())\n",
      "\n",
      "# json as a dictionary\n",
      "print baltJson['meta']['view']['id']\n",
      "print baltJson['meta']['view']['name']\n",
      "print baltJson['meta']['view']['attribution']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dz54-2aru\n",
        "Baltimore Fixed Speed Cameras\n",
        "Department of Transportation\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Writing Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes, you'll want to create a subset of a given data source. The following simply reads in the same Baltimore data, creates a subset, and saves it off to a different .csv file.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# first read the csv file.  PLEASE note that this is dealing with .csv files only.  \n",
      "#If you're reading from an xls or xlsx, it can cause formatting issues.\n",
      "cameraData = pd.read_csv('Baltimore_Fixed_Speed_Cameras.csv')\n",
      "\n",
      "# take a subset of the columns\n",
      "grabbedData = cameraData.ix[:,3:]\n",
      "\n",
      "# then save it to a different csv file\n",
      "# this is equivalent to R's write.table() command\n",
      "grabbedData.to_csv('baltimore_subset.csv', sep=',', index=False)\n",
      "\n",
      "newData = pd.read_csv('baltimore_subset.csv')\n",
      "newData.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>crossStreet</th>\n",
        "      <th>intersection</th>\n",
        "      <th>Location 1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>   Benson Ave</td>\n",
        "      <td>     Caton Ave &amp; Benson Ave</td>\n",
        "      <td> (39.2693779962, -76.6688185297)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>   Benson Ave</td>\n",
        "      <td>     Caton Ave &amp; Benson Ave</td>\n",
        "      <td> (39.2693157898, -76.6689698176)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> Pine Heights</td>\n",
        "      <td> Wilkens Ave &amp; Pine Heights</td>\n",
        "      <td>  (39.2720252302, -76.676960806)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      33rd St</td>\n",
        "      <td>     The Alameda  &amp; 33rd St</td>\n",
        "      <td> (39.3285013141, -76.5953545714)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  The Alameda</td>\n",
        "      <td>      E 33rd  &amp; The Alameda</td>\n",
        "      <td> (39.3283410623, -76.5953594625)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "    crossStreet                intersection                       Location 1\n",
        "0    Benson Ave      Caton Ave & Benson Ave  (39.2693779962, -76.6688185297)\n",
        "1    Benson Ave      Caton Ave & Benson Ave  (39.2693157898, -76.6689698176)\n",
        "2  Pine Heights  Wilkens Ave & Pine Heights   (39.2720252302, -76.676960806)\n",
        "3       33rd St      The Alameda  & 33rd St  (39.3285013141, -76.5953545714)\n",
        "4   The Alameda       E 33rd  & The Alameda  (39.3283410623, -76.5953594625)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Placeholder for web scraping. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}